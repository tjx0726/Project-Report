% Encoding: UTF-8

@Book{intro-rl,
  title     = {Reinforcement Learning: An Introduction},
  publisher = {The MIT Press},
  year      = {1998},
  author    = {Richard S. Sutton and Andrew G. Barto},
  isbn      = {9780262193986},
  date      = {1998-05-11},
  ean       = {9780262193986},
  pagetotal = {338},
  url       = {http://www.ebook.de/de/product/3643662/richard_s_sutton_andrew_g_barto_reinforcement_learning.html},
}

@Article{human-level,
  author    = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  year      = {2015},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  month     = {feb},
  doi       = {10.1038/nature14236},
  publisher = {Springer Nature},
}

@Misc{flappy-bird1,
  author       = {Ben Lau},
  title        = {Using Keras and Deep Q-Network to Play FlappyBird},
  howpublished = {Website},
  month        = {07},
  year         = {2016},
  note         = {\url{https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html}},
  url          = {https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html},
}

@Misc{flappy-bird2,
  author       = {Yenchen Lin},
  title        = {Using Deep Q-Network to Learn How To Play Flappy Bird},
  howpublished = {Website},
  month        = {03},
  year         = {2016},
  note         = {\url{https://github.com/yenchenlin/DeepLearningFlappyBird}},
  url          = {https://github.com/yenchenlin/DeepLearningFlappyBird},
}

@TechReport{deep-learning-methods-and-applications,
  author      = {Deng, Li and Yu, Dong},
  title       = {Deep Learning: Methods and Applications},
  institution = {Microsoft},
  year        = {2014},
  month       = {May},
  note        = {\url{https://www.microsoft.com/en-us/research/publication/deep-learning-methods-and-applications/}},
  abstract    = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.

In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme.

In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
  publisher   = {NOW Publishers},
  url         = {https://www.microsoft.com/en-us/research/publication/deep-learning-methods-and-applications/},
}

@Article{Deep-Learning,
  author    = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
  title     = {Deep learning},
  journal   = {Nature},
  year      = {2015},
  volume    = {521},
  number    = {7553},
  pages     = {436--444},
  month     = {may},
  doi       = {10.1038/nature14539},
  publisher = {Springer Nature},
}

@Article{Schm14,
  author       = {Juergen Schmidhuber},
  title        = {Deep Learning in Neural Networks: An Overview},
  abstract     = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  date         = {2014-04-30},
  doi          = {10.1016/j.neunet.2014.09.003},
  eprint       = {1404.7828v4},
  eprintclass  = {cs.NE},
  eprinttype   = {arXiv},
  file         = {online:http\://arxiv.org/pdf/1404.7828v4:PDF},
  journaltitle = {Neural Networks, Vol 61, pp 85-117, Jan 2015},
  keywords     = {cs.NE, cs.LG},
}

@Misc{DQN,
  author       = {DeepMind},
  title        = {DQN},
  howpublished = {Website},
  note         = {\url{https://deepmind.com/research/dqn/}},
  url          = {https://deepmind.com/research/dqn/},
}

@Misc{Deep-RL,
  author       = {David Silver},
  title        = {Deep Reinforcement Learning},
  howpublished = {Blog},
  month        = {06},
  year         = {2016},
  note         = {\url{https://deepmind.com/blog/deep-reinforcement-learning/}},
  url          = {https://deepmind.com/blog/deep-reinforcement-learning/},
}

@Book{thorndike1898animal,
  title     = {Animal Intelligence: An Experimental Study of the Associative Processes in Animals},
  publisher = {Macmillan},
  year      = {1898},
  author    = {Thorndike, E.L.},
  number    = {no. 4},
  series    = {Animal Intelligence: An Experimental Study of the Associative Processes in Animals},
  lccn      = {03012371},
  url       = {https://books.google.co.uk/books?id=paQ-AQAAMAAJ},
}

@Article{Schultz_1997,
  author    = {W. Schultz and P. Dayan and P. R. Montague},
  title     = {A Neural Substrate of Prediction and Reward},
  journal   = {Science},
  year      = {1997},
  volume    = {275},
  number    = {5306},
  pages     = {1593--1599},
  month     = {mar},
  doi       = {10.1126/science.275.5306.1593},
  publisher = {American Association for the Advancement of Science ({AAAS})},
}

@Article{tvl1,
  author    = {Javier S{\'{a}}nchez P{\'{e}}rez and Enric Meinhardt-Llopis and Gabriele Facciolo},
  title     = {{TV}-L1 Optical Flow Estimation},
  journal   = {Image Processing On Line},
  year      = {2013},
  volume    = {3},
  pages     = {137--150},
  month     = {jul},
  doi       = {10.5201/ipol.2013.26},
  publisher = {Image Processing On Line},
}

@Misc{ldd,
  title        = {LEGO Digital Designer},
  howpublished = {Website},
  note         = {\url{http://ldd.lego.com/}},
}

@Article{doubleQ,
  author      = {Hado van Hasselt and Arthur Guez and David Silver},
  title       = {Deep Reinforcement Learning with Double Q-learning},
  journal     = {arXiv},
  year        = {2015},
  abstract    = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
  date        = {2015-09-22},
  eprint      = {1509.06461v3},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1509.06461v3:PDF},
  keywords    = {cs.LG},
}

@PhdThesis{Watkins:1989,
  author          = {Watkins, Christopher John Cornish Hellaby},
  title           = {Learning from Delayed Rewards},
  school          = {King's College},
  year            = {1989},
  address         = {Cambridge, UK},
  month           = {May},
  bib2html_rescat = {Parameter},
  url             = {http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf},
}

@TechReport{Q-l,
  author      = {CHRISTOPHER J.C.H. WATKINS and PETER DAYAN},
  title       = {Technical Note:Q-Learning},
  institution = {Kluwer Academic Publishers},
  year        = {1992},
}

@Article{Bengio_2009,
  author    = {Y. Bengio},
  title     = {Learning Deep Architectures for {AI}},
  journal   = {Foundations and Trends{\textregistered} in Machine Learning},
  year      = {2009},
  volume    = {2},
  number    = {1},
  pages     = {1--127},
  doi       = {10.1561/2200000006},
  publisher = {Now Publishers},
}

@Article{Schmidhuber_2015,
  author    = {Juergen Schmidhuber},
  title     = {Deep Learning},
  journal   = {Scholarpedia},
  year      = {2015},
  volume    = {10},
  number    = {11},
  pages     = {32832},
  doi       = {10.4249/scholarpedia.32832},
  publisher = {Scholarpedia},
}

@Book{Goodfellow-et-al-2016,
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  note      = {\url{http://www.deeplearningbook.org}},
}

@Comment{jabref-meta: databaseType:bibtex;}
